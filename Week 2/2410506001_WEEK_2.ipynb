{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/figojulioez/Laporan-praktikum-Big-Data/blob/main/Week%201/2410506001_WEEK_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqGWns4anClR"
   },
   "source": [
    "## Latihan 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTScCgKuspGT",
    "outputId": "89f8a74e-55be-4611-fe26-6eba39fd5b93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/01 01:48:47 WARN Utils: Your hostname, figo-Vostro-V131, resolves to a loopback address: 127.0.1.1; using 10.32.117.75 instead (on interface wlp9s0)\n",
      "25/09/01 01:48:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/01 01:48:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan import dari pyspark.sql untuk menggunakan SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session hal ini dilakukan sebagai entry point untuk mengakses module - module dari pyspark\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "# DataFrame awalnya berupa array yang didalmmnya memiliki kumpulan data denga struktur data tuple dimana data pertama dalam tupple sebagai kolom pertama dan data kedua dalam tuple sebagai kolom kedua\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "\n",
    "# Menentukan kolom atau field yang nantinya akan tampil di dataframe\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "\n",
    "# Menggunakan method createDataFrame untuk mengubah list dengan kumpulan tuple menjadi sebuah table\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Fy5wkWqnGsF"
   },
   "source": [
    "## TUGAS 1 Jalankan kode di atas dan buat modifikasi dengan menambahkan data lain berupa kolom pekerjaan, hobi dan gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFx3X-qPnNZ3",
    "outputId": "544ad07e-010d-45db-a562-19a846a119bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/01 01:49:03 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------------+--------------+-----------+\n",
      "|Nama|Usia|    Pekerjaan|          Hobi|     Gender|\n",
      "+----+----+-------------+--------------+-----------+\n",
      "|Figo|  19|IT Programmer|        Futsal|Laki - laki|\n",
      "|Zico|  15|Web Developer| Nonton Drakor|Laki - laki|\n",
      "|Kana|   8| AI Developer|  Nonton Anime|Laki - laki|\n",
      "|Lala|  23|IT Consultant|Nonoton Dracin|  Perempuan|\n",
      "+----+----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan import dari pyspark.sql untuk menggunakan SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session hal ini dilakukan sebagai entry point untuk mengakses module - module dari pyspark\n",
    "spark = SparkSession.builder.appName(\"FigoSession\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "# DataFrame awalnya berupa array yang didalmmnya memiliki kumpulan data denga struktur data tuple dimana data pertama dalam tupple sebagai kolom pertama dan data kedua dalam tuple sebagai kolom kedua\n",
    "data = [(\"Figo\", 19, \"IT Programmer\", \"Futsal\", \"Laki - laki\",), (\"Zico\", 15, \"Web Developer\", 'Nonton Drakor',\"Laki - laki\"), (\"Kana\", 8, \"AI Developer\",'Nonton Anime','Laki - laki'), (\"Lala\", 23, \"IT Consultant\", 'Nonoton Dracin',\"Perempuan\")]\n",
    "\n",
    "# Menentukan kolom atau field yang nantinya akan tampil di dataframe\n",
    "columns = [\"Nama\", \"Usia\", \"Pekerjaan\",'Hobi',\"Gender\"]\n",
    "\n",
    "# Menggunakan method createDataFrame untuk mengubah list dengan kumpulan tuple menjadi sebuah table\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpstZNHpJFkK"
   },
   "source": [
    "## Latihan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eo2poDAI50C",
    "outputId": "e1f574a8-bf79-4655-dcd2-2fff70ff75e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/01 01:49:03 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n",
      "+----+----+\n",
      "|Nama|Usia|\n",
      "+----+----+\n",
      "| Ali|  34|\n",
      "|Dina|  45|\n",
      "+----+----+\n",
      "\n",
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|    32.75|\n",
      "+---------+\n",
      "\n",
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "| Dina|  45|\n",
      "|  Ali|  34|\n",
      "|Citra|  29|\n",
      "| Budi|  23|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan import dari pyspark.sql untuk menggunakan SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Memulai Spark session hal ini dilakukan sebagai entry point untuk mengakses module - module dari pyspark\n",
    "spark = SparkSession.builder.appName(\"BigDataPractice\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "# DataFrame awalnya berupa array yang didalmmnya memiliki kumpulan data denga struktur data tuple dimana data pertama dalam tupple sebagai kolom pertama dan data kedua dalam tuple sebagai kolom kedua\n",
    "data = [(\"Ali\", 34), (\"Budi\", 23), (\"Citra\", 29), (\"Dina\", 45)]\n",
    "\n",
    "# Menentukan kolom atau field yang nantinya akan tampil di dataframe\n",
    "columns = [\"Nama\", \"Usia\"]\n",
    "\n",
    "# Menggunakan method createDataFrame untuk mengubah list dengan kumpulan tuple menjadi sebuah table\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan DataFrame\n",
    "df.show()\n",
    "\n",
    "# Filtering data\n",
    "# Filetering data berdasarkan field atau kolom usia dimana data yang ditampilkan hanya data yang usianya di atas 30\n",
    "# Hasil filtering akan disimpan pada variabel df_filtered\n",
    "df_filtered = df.filter(df['Usia'] > 30)\n",
    "# Menampilkan hasil filtering\n",
    "df_filtered.show()\n",
    "\n",
    "# Menghitung rata-rata usia\n",
    "# melakukan import dari pyspark.sql.function untuk menggunakan fungsi avg agar dapat menghitung rata - rata\n",
    "from pyspark.sql.functions import avg\n",
    "# DataFrame akan di grouping lalu menjalankan fungsi agregasi yaitu avg untuk menghitung rata - rata usia lalu menampilkan hasilnya\n",
    "df.groupBy().agg(avg(\"Usia\")).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan usia\n",
    "# Melakukan pengurutan berdasarkan usia dimana pada parameter kedua asc nya false maka pengurutan dilakukan dari yang terbesar hingga terkecil\n",
    "df_sorted = df.orderBy(\"Usia\", ascending=False)\n",
    "# Menampilkan DataFrame yang sudah diurutkan\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZrPDnLaLZq2"
   },
   "source": [
    "## Tugas 2 Lakukan filter, penghitungan rata-rata, dan pengurutan data menggunakan PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teeEjm9YMoO9",
    "outputId": "fe3cd238-e94c-495f-fe35-d76023e2d96a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/01 01:49:07 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Nama Barang|Harga|\n",
      "+-----------+-----+\n",
      "|  Sari Roti| 5000|\n",
      "+-----------+-----+\n",
      "\n",
      "+----------+\n",
      "|avg(Harga)|\n",
      "+----------+\n",
      "|    3125.0|\n",
      "+----------+\n",
      "\n",
      "+-----------+-----+\n",
      "|Nama Barang|Harga|\n",
      "+-----------+-----+\n",
      "|   Sunlight| 2000|\n",
      "|     Nabati| 2500|\n",
      "|    Indomie| 3000|\n",
      "|  Sari Roti| 5000|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melakukan import dari pyspark.sql untuk menggunakan SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkSession\").getOrCreate()\n",
    "\n",
    "# Membuat DataFrame sederhana\n",
    "# DataFrame awalnya berupa array yang didalmmnya memiliki kumpulan data denga struktur data tuple dimana data pertama dalam tupple sebagai kolom pertama dan data kedua dalam tuple sebagai kolom kedua\n",
    "data = [(\"Indomie\", 3000), (\"Sunlight\", 2000), (\"Sari Roti\", 5000), (\"Nabati\", 2500)]\n",
    "\n",
    "# Menentukan kolom atau field yang nantinya akan tampil di dataframe\n",
    "columns = [\"Nama Barang\", \"Harga\"]\n",
    "\n",
    "# Menggunakan method createDataFrame untuk mengubah list dengan kumpulan tuple menjadi sebuah table\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Filtering data\n",
    "# Filetering data berdasarkan field atau kolom usia dimana data yang ditampilkan hanya data yang usianya di atas 30\n",
    "# Hasil filtering akan disimpan pada variabel df_filtered\n",
    "df_filtered = df.filter(df['Harga'] > 3000)\n",
    "# Menampilkan hasil filtering\n",
    "df_filtered.show()\n",
    "\n",
    "\n",
    "# Menghitung rata-rata harga barang\n",
    "# melakukan import dari pyspark.sql.function untuk menggunakan fungsi avg agar dapat menghitung rata - rata\n",
    "from pyspark.sql.functions import avg\n",
    "# DataFrame akan di grouping lalu menjalankan fungsi agregasi yaitu avg untuk menghitung rata - rata harga barang lalu menampilkan hasilnya\n",
    "df.groupBy().agg(avg(df[\"Harga\"])).show()\n",
    "\n",
    "# Mengurutkan data berdasarkan Harga Barang\n",
    "# Melakukan pengurutan berdasarkan Harga Barang dimana pada parameter kedua asc nya true maka pengurutan dilakukan dari yang terkecil hingga terbesar\n",
    "df_sorted = df.orderBy(\"Harga\", ascending=True)\n",
    "# Menampilkan DataFrame yang sudah diurutkan\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkRB9gIdX1i8"
   },
   "source": [
    "## Latihan 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "wFYLMt5iX6FU",
    "outputId": "54b57f8d-6605-467e-ebbf-f6ed3ccfecf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Usia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budi</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Citra</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nama  Usia\n",
       "0    Ali    34\n",
       "1   Budi    23\n",
       "2  Citra    29\n",
       "3   Dina    45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengimport module pandas lalu di berikan alias pd agar module dapat digunakan lebih ringkas\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Menampilkan DataFrame Pandas\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYjrVLGzYdsH"
   },
   "source": [
    "## Tugas 3 Modifikasi DataFrame Pandas dengan menambahkan kolom baru dan melakukan operasi seperti filtering data berdasarkan usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "uuGuvZ7XYZD4",
    "outputId": "93b33576-5624-4522-88d5-d192ac6d4082"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama</th>\n",
       "      <th>Usia</th>\n",
       "      <th>Hobi</th>\n",
       "      <th>Pekerjaan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali</td>\n",
       "      <td>34</td>\n",
       "      <td>Nonton Drakor</td>\n",
       "      <td>IT Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dina</td>\n",
       "      <td>45</td>\n",
       "      <td>Nonton Donghua</td>\n",
       "      <td>NEET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nama  Usia            Hobi      Pekerjaan\n",
       "0   Ali    34   Nonton Drakor  IT Consultant\n",
       "3  Dina    45  Nonton Donghua           NEET"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengimport module pandas lalu di berikan alias pd agar module dapat digunakan lebih ringkas\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45], \"Hobi\": [\"Nonton Drakor\", 'Nonton Dracin', 'Nonton Anime', 'Nonton Donghua'], \"Pekerjaan\" : ['IT Consultant', 'Web Developer', 'Programmer', 'NEET']}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# melakukan pemfilteran pada pandas, pemfilteran dilakukan secara langsung tanpa method tambahan\n",
    "df_pandas_filtered_by_usia = df_pandas[df_pandas['Usia'] > 30]\n",
    "\n",
    "# Menampilkan DataFrame Pandas\n",
    "df_pandas_filtered_by_usia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3TBUzwajd6h"
   },
   "source": [
    "## LATIHAN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "vkXExRsijdnF",
    "outputId": "d37ea96b-8e48-476b-b861-84713ca9dc8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Nama  Usia Pekerjaan\n",
      "0    Ali    34    Dokter\n",
      "1   Budi    23      Guru\n",
      "2  Citra    29  Insinyur\n",
      "3   Dina    45   Perawat\n",
      "            Usia\n",
      "count   4.000000\n",
      "mean   32.750000\n",
      "std     9.322911\n",
      "min    23.000000\n",
      "25%    27.500000\n",
      "50%    31.500000\n",
      "75%    36.750000\n",
      "max    45.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mengimport module pandas lalu di berikan alias pd agar module dapat digunakan lebih ringkas\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Usia\": [34, 23, 29, 45]}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_pandas = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas_2 = {\"Nama\": [\"Ali\", \"Budi\", \"Citra\", \"Dina\"], \"Pekerjaan\": [\"Dokter\", \"Guru\", \"Insinyur\", \"Perawat\"]}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_pandas_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Join antara dua DataFrame\n",
    "# Melakukan join atau menyatukan 2 DataFrame antara df_pandas dengan df_pandas dimana penyatuan berdasarkan field atau key Nama\n",
    "df_joined = pd.merge(df_pandas, df_pandas_2, on=\"Nama\")\n",
    "# Menampilkan DataFrame\n",
    "print(df_joined)\n",
    "\n",
    "# Menghitung statistik deskriptif\n",
    "print(df_pandas.describe())\n",
    "\n",
    "# Plotting Data\n",
    "# Melakukan import library dari matplotlib untuk membuat grafik\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# grafik yang dibuat berdasarkan field usia dimana grafik yang digunakan bertipe bar\n",
    "df_pandas['Usia'].plot(kind='bar')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzPrLuvfso2J"
   },
   "source": [
    "## Tugas 4 Lakukan penggabungan DataFrame dan visualisasikan data dengan Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "JLOC_jrhsneI",
    "outputId": "64ae62b4-1854-4387-8322-260d91af10cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Nama      Gaji       Job Desk\n",
      "0     Figo  90000000  IT Consultant\n",
      "1     Zico  12000000  Web Developer\n",
      "2     Kana  60000000     Programmer\n",
      "3  Sabrina  45000000           NEET\n",
      "               Gaji\n",
      "count  4.000000e+00\n",
      "mean   5.175000e+07\n",
      "std    3.243840e+07\n",
      "min    1.200000e+07\n",
      "25%    3.675000e+07\n",
      "50%    5.250000e+07\n",
      "75%    6.750000e+07\n",
      "max    9.000000e+07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mengimport module pandas lalu di berikan alias pd agar module dapat digunakan lebih ringkas\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat DataFrame Pandas\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas = {\"Nama\": [\"Figo\", \"Zico\", \"Kana\", \"Sabrina\"], \"Gaji\": [90000000, 12000000, 60000000, 45000000]}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_panda = pd.DataFrame(data_pandas)\n",
    "\n",
    "# Membuat DataFrame kedua\n",
    "# Berbeda dengan pyspark dimana mengubah list dengan kumpulan tuple menjadi DataFrame di pandas mengubah sebuah Dictionary menjadi DataFrame\n",
    "data_pandas_2 = {\"Nama\": [\"Figo\", \"Zico\", \"Kana\", \"Sabrina\"], \"Job Desk\": [\"IT Consultant\", \"Web Developer\", \"Programmer\", \"NEET\"]}\n",
    "# Mengubah dictionary yang dibuat menjadi sebuah DataFrame\n",
    "df_panda_2 = pd.DataFrame(data_pandas_2)\n",
    "\n",
    "# Join antara dua DataFrame\n",
    "# Melakukan join atau menyatukan 2 DataFrame antara df_panda dengan df_panda2 dimana penyatuan berdasarkan field atau key Nama\n",
    "df_joined = pd.merge(df_panda, df_panda_2, on=\"Nama\")\n",
    "# Menampilkan DataFrame\n",
    "print(df_joined)\n",
    "\n",
    "# Menghitung statistik deskriptif\n",
    "print(df_panda.describe())\n",
    "\n",
    "# Plotting Data\n",
    "# Melakukan import library dari matplotlib untuk membuat grafik\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# grafik yang dibuat berdasarkan field usia dimana grafik yang digunakan bertipe bar\n",
    "df_panda['Gaji'].plot(kind='bar')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avKwbxGYznlG"
   },
   "source": [
    "## Latihan 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oK3Vk42_zqg7",
    "outputId": "6c60bf70-9aea-4742-f994-b8ed854f8166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Nama Barang  Harga\n",
       " 0     Indomie   3000\n",
       " 1    Sunlight   2000\n",
       " 2   Sari Roti   5000\n",
       " 3      Nabati   2500,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengonversi DataFrame dari PySpark ke Pandas\n",
    "# Dari DataFrame spark yang berisi Nama Barang dan Harga diubah menjadi DataFrame Pandas\n",
    "df_pandas_from_spark = df.toPandas()\n",
    "\n",
    "# Mengonversi DataFrame dari Pandas ke PySpark\n",
    "# Dari DataFrame pandas yang berisi field nama dan usia diubah menjadi DataFrame Spark\n",
    "df_spark_from_pandas = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Menampilkan DataFrame hasil konversi\n",
    "df_pandas_from_spark, df_spark_from_pandas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou9CUNWj8re3"
   },
   "source": [
    "## Tugas 5  Gunakan metode ini untuk menggabungkan data yang Anda buat di PySpark dengan data dari Pandas, kemudian lakukan analisis sederhana seperti menghitung rata-rata usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ta-1V3H8q9G",
    "outputId": "8782e858-e468-4e17-b96d-0f0f39783a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nama  Usia      Pekerjaan\n",
      "0  Figo    19  IT Consultant\n",
      "1  Zico    20  Web Developer\n",
      "2  Kana    12     Programmer\n",
      "3  Lala    21           NEET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/01 01:49:13 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Nama|    Gaji|\n",
      "+----+--------+\n",
      "|Figo|20000000|\n",
      "|Zico|50000000|\n",
      "|Kana|15000000|\n",
      "|Lala|10000000|\n",
      "+----+--------+\n",
      "\n",
      "None\n",
      "   Nama      Gaji\n",
      "0  Figo  20000000\n",
      "1  Zico  50000000\n",
      "2  Kana  15000000\n",
      "3  Lala  10000000\n",
      "+-----+----+\n",
      "| Nama|Usia|\n",
      "+-----+----+\n",
      "|  Ali|  34|\n",
      "| Budi|  23|\n",
      "|Citra|  29|\n",
      "| Dina|  45|\n",
      "+-----+----+\n",
      "\n",
      "None\n",
      "   Nama      Gaji  Usia      Pekerjaan\n",
      "0  Figo  20000000    19  IT Consultant\n",
      "1  Zico  50000000    20  Web Developer\n",
      "2  Kana  15000000    12     Programmer\n",
      "3  Lala  10000000    21           NEET\n",
      "+---------+\n",
      "|avg(Usia)|\n",
      "+---------+\n",
      "|     18.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import module pandas dan pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inisiasi entry point spark\n",
    "spark = SparkSession.builder.appName(\"Session Tugas 5\").getOrCreate()\n",
    "\n",
    "# Membuat sebuah dictionary untuk mengubahnya menjadi DataFrame pada pandas\n",
    "data_for_pandas = {\"Nama\": [\"Figo\", \"Zico\", \"Kana\", \"Lala\"], \"Usia\": [19, 20, 12, 21], \"Pekerjaan\": [\"IT Consultant\", \"Web Developer\", \"Programmer\", \"NEET\"]}\n",
    "\n",
    "# Membuat sebuah list yang didalamnya terdapat kumpulan tupple untuk mengubahnya menjadi DataFrame Spark\n",
    "data_for_spark = [(\"Figo\", 20000000), (\"Zico\", 50000000), (\"Kana\", 15000000), (\"Lala\", 10000000)]\n",
    "# Membuat kolom pada spark\n",
    "spark_col = [\"Nama\", \"Gaji\"]\n",
    "\n",
    "# Membuat DataFrame spark dan DataFrame pandas\n",
    "df_pandas = pd.DataFrame(data_for_pandas)\n",
    "df_spark = spark.createDataFrame(data_for_spark, spark_col)\n",
    "\n",
    "# Menampilkan DataFrame pandas dan DataFrame PySpark\n",
    "print(df_pandas)\n",
    "print(df_spark.show())\n",
    "\n",
    "# Mengubah DataFrame pandas dari spark\n",
    "df_pandas_from_spark = df_spark.toPandas()\n",
    "\n",
    "\n",
    "print(df_pandas_from_spark)\n",
    "print(df_spark_from_pandas.show())\n",
    "\n",
    "# Menggabungkan data yang dibuat dengan pandas dan pyspark berdasarkan nama\n",
    "df_merge = pd.merge(df_pandas_from_spark, df_pandas, on=\"Nama\")\n",
    "print(df_merge)\n",
    "\n",
    "# Mengubah DataFrame spark dari pandas\n",
    "df_spark_from_pandas = spark.createDataFrame(df_merge)\n",
    "\n",
    "# Membuat analisis untuk menghitung rata - rata usia\n",
    "# melakukan import dari pyspark.sql.function untuk menggunakan fungsi avg agar dapat menghitung rata - rata\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# DataFrame akan di grouping lalu menjalankan fungsi agregasi yaitu avg untuk menghitung rata - rata usia lalu menampilkan hasilnya\n",
    "df_spark_from_pandas.groupBy().agg(avg(df_spark_from_pandas[\"Usia\"])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS8JtxfpG6LX"
   },
   "source": [
    "## Tugas 6 Gabungkan data dari PySpark dan Pandas, lalu lakukan operasi statistik seperti menghitung nilai maksimum usia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeyBcCQKHN08",
    "outputId": "903abffc-fdf1-40ab-aa73-d0adef700cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nama  Usia      Pekerjaan\n",
      "0  Figo    19  IT Consultant\n",
      "1  Zico    20  Web Developer\n",
      "2  Kana    12     Programmer\n",
      "3  Lala    21           NEET\n",
      "+----+--------+\n",
      "|Nama|    Gaji|\n",
      "+----+--------+\n",
      "|Figo|20000000|\n",
      "|Zico|50000000|\n",
      "|Kana|15000000|\n",
      "|Lala|10000000|\n",
      "+----+--------+\n",
      "\n",
      "None\n",
      "   Nama      Gaji\n",
      "0  Figo  20000000\n",
      "1  Zico  50000000\n",
      "2  Kana  15000000\n",
      "3  Lala  10000000\n",
      "+----+--------+----+-------------+\n",
      "|Nama|    Gaji|Usia|    Pekerjaan|\n",
      "+----+--------+----+-------------+\n",
      "|Figo|20000000|  19|IT Consultant|\n",
      "|Zico|50000000|  20|Web Developer|\n",
      "|Kana|15000000|  12|   Programmer|\n",
      "|Lala|10000000|  21|         NEET|\n",
      "+----+--------+----+-------------+\n",
      "\n",
      "None\n",
      "   Nama      Gaji  Usia      Pekerjaan\n",
      "0  Figo  20000000    19  IT Consultant\n",
      "1  Zico  50000000    20  Web Developer\n",
      "2  Kana  15000000    12     Programmer\n",
      "3  Lala  10000000    21           NEET\n",
      "+---------+\n",
      "|max(Usia)|\n",
      "+---------+\n",
      "|       21|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import module pandas dan pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inisiasi entry point spark\n",
    "spark = SparkSession.builder.appName(\"Session Tugas 5\").getOrCreate()\n",
    "\n",
    "# Membuat sebuah dictionary untuk mengubahnya menjadi DataFrame pada pandas\n",
    "data_for_pandas = {\"Nama\": [\"Figo\", \"Zico\", \"Kana\", \"Lala\"], \"Usia\": [19, 20, 12, 21], \"Pekerjaan\": [\"IT Consultant\", \"Web Developer\", \"Programmer\", \"NEET\"]}\n",
    "\n",
    "# Membuat sebuah list yang didalamnya terdapat kumpulan tupple untuk mengubahnya menjadi DataFrame Spark\n",
    "data_for_spark = [(\"Figo\", 20000000), (\"Zico\", 50000000), (\"Kana\", 15000000), (\"Lala\", 10000000)]\n",
    "# Membuat kolom pada spark\n",
    "spark_col = [\"Nama\", \"Gaji\"]\n",
    "\n",
    "# Membuat DataFrame spark dan DataFrame pandas\n",
    "df_pandas = pd.DataFrame(data_for_pandas)\n",
    "df_spark = spark.createDataFrame(data_for_spark, spark_col)\n",
    "\n",
    "# Menampilkan DataFrame pandas dan DataFrame PySpark\n",
    "print(df_pandas)\n",
    "print(df_spark.show())\n",
    "\n",
    "# Mengubah DataFrame pandas dari spark\n",
    "df_pandas_from_spark = df_spark.toPandas()\n",
    "\n",
    "\n",
    "print(df_pandas_from_spark)\n",
    "print(df_spark_from_pandas.show())\n",
    "\n",
    "# Menggabungkan data yang dibuat dengan pandas dan pyspark berdasarkan nama\n",
    "df_merge = pd.merge(df_pandas_from_spark, df_pandas, on=\"Nama\")\n",
    "print(df_merge)\n",
    "\n",
    "# Mengubah DataFrame spark dari pandas\n",
    "df_spark_from_pandas = spark.createDataFrame(df_merge)\n",
    "\n",
    "# Membuat analisis untuk menghitung rata - rata usia\n",
    "# melakukan import dari pyspark.sql.function untuk menggunakan fungsi max agar dapat menghitung nilai maksimum\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "# DataFrame akan di grouping lalu menjalankan fungsi agregasi yaitu avg untuk menghitung nilai maksimum usia lalu menampilkan hasilnya\n",
    "df_spark_from_pandas.groupBy().agg(max(df_spark_from_pandas[\"Usia\"])).show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOW3d93bXLPPNMUinBNNiSD",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
