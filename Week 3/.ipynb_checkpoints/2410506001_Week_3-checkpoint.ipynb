{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29c8e3f7-8241-41b7-ab00-986280cae5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 17:13:38 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|       James|     Sales|  3000|\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "|       Maria|   Finance|  3000|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n",
    "\n",
    "data = [('James', 'Sales', 3000),\n",
    "        ('Michael', 'Sales', 4600),\n",
    "        ('Robert', 'Sales', 4100),\n",
    "        ('Maria', 'Finance', 3000)]\n",
    "columns = ['EmployeeName', 'Department', 'Salary']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30f1d17a-8166-4783-88d1-fa8f968e0a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|EmployeeName|Salary|\n",
      "+------------+------+\n",
      "|       James|  3000|\n",
      "|     Michael|  4600|\n",
      "|      Robert|  4100|\n",
      "|       Maria|  3000|\n",
      "+------------+------+\n",
      "\n",
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "+------------+----------+------+\n",
      "\n",
      "+----------+-----------+\n",
      "|Department|avg(Salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|     3900.0|\n",
      "|   Finance|     3000.0|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh operasi transformasi DataFrame\n",
    "df.select('EmployeeName', 'Salary').show()\n",
    "df.filter(df['Salary'] > 3000).show()\n",
    "df.groupBy('Department').avg('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1690c84-b6f1-4269-bcbb-0e3c6f946d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+-----------+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|\n",
      "+------------+----------+------+-----------+\n",
      "|       James|     Sales|  3000|      300.0|\n",
      "|     Michael|     Sales|  4600|      460.0|\n",
      "|      Robert|     Sales|  4100|      410.0|\n",
      "|       Maria|   Finance|  3000|      300.0|\n",
      "+------------+----------+------+-----------+\n",
      "\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "|       James|     Sales|  3000|      300.0|           3300.0|\n",
      "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
      "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
      "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh manipulasi tipe data kompleks\n",
    "df = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
    "df.show()\n",
    "df = df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4b63c45-3e92-4b99-a952-520fae35d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+-----------+-----------------+----+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|Rank|\n",
      "+------------+----------+------+-----------+-----------------+----+\n",
      "|       Maria|   Finance|  3000|      300.0|           3300.0|   1|\n",
      "|       James|     Sales|  3000|      300.0|           3300.0|   1|\n",
      "|      Robert|     Sales|  4100|      410.0|           4510.0|   2|\n",
      "|     Michael|     Sales|  4600|      460.0|           5060.0|   3|\n",
      "+------------+----------+------+-----------+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh menggunakan window functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
    "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c89f7-7471-4f82-af36-cc1af13aff1c",
   "metadata": {},
   "source": [
    "## Tugas 1: Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b314a247-0283-46be-9a96-8efe0bfa4873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----+\n",
      "|NamaPegawai|          Jabatan|Gaji|\n",
      "+-----------+-----------------+----+\n",
      "|       Budi|    IT Consultant|5000|\n",
      "|       Figo|      IT Software|4000|\n",
      "|       Kana|Android Developer|3500|\n",
      "|       Zico|    Web Developer|3000|\n",
      "+-----------+-----------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/10 17:13:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Melakukan import SparkSession untuk memulai atau mendapatkan sebuah sesi dari library pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Mendapatkan atau membuat sebuah sesi bernama \"Pertemuan 3\" untuk agar dapat mengakses library pyspark\n",
    "spark = SparkSession.builder.appName(\"Pertemuan3\").getOrCreate()\n",
    "\n",
    "# Membuat sebuah list yang di dalamnya terdapat beberapa tupple untuk membuat sebuah dataframe pyspark\n",
    "data = [\n",
    "    ('Budi', 'IT Consultant', 5000),     # Pekerjaan paling sulit\n",
    "    ('Figo', 'IT Software', 4000),       # Pekerjaan cukup sulit\n",
    "    ('Kana', 'Android Developer', 3500), # Pekerjaan Menengah\n",
    "    ('Zico', 'Web Developer', 3000)      # Pekerjaan yang Lebih mudah\n",
    "]\n",
    "# Membuat sebuah list berisi nama - nama kolom untuk dataframe dari data di atas\n",
    "columns = [\"NamaPegawai\", \"Jabatan\", \"Gaji\"]\n",
    "\n",
    "# Membuat sebuah dataframe\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menampilkan data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ee5bb-fc3b-4ac1-8d8a-15055a6ca0c8",
   "metadata": {},
   "source": [
    "## Tugas 2: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4efd132c-70a4-4305-b2c2-1e383ec70ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|NamaPegawai|Gaji|\n",
      "+-----------+----+\n",
      "|       Budi|5000|\n",
      "|       Figo|4000|\n",
      "|       Kana|3500|\n",
      "|       Zico|3000|\n",
      "+-----------+----+\n",
      "\n",
      "+-----------+-----------------+----+\n",
      "|NamaPegawai|          Jabatan|Gaji|\n",
      "+-----------+-----------------+----+\n",
      "|       Budi|    IT Consultant|5000|\n",
      "|       Figo|      IT Software|4000|\n",
      "|       Kana|Android Developer|3500|\n",
      "+-----------+-----------------+----+\n",
      "\n",
      "+-----------------+---------+\n",
      "|          Jabatan|avg(Gaji)|\n",
      "+-----------------+---------+\n",
      "|    IT Consultant|   5000.0|\n",
      "|      IT Software|   4000.0|\n",
      "|Android Developer|   3500.0|\n",
      "|    Web Developer|   3000.0|\n",
      "+-----------------+---------+\n",
      "\n",
      "+----------------+\n",
      "|Rata - Rata Gaji|\n",
      "+----------------+\n",
      "|          3875.0|\n",
      "+----------------+\n",
      "\n",
      "+------------------------+\n",
      "|Nilai Maksimum Dari Gaji|\n",
      "+------------------------+\n",
      "|                    5000|\n",
      "+------------------------+\n",
      "\n",
      "+----------------------+\n",
      "|Total Keseluruhan Gaji|\n",
      "+----------------------+\n",
      "|                 15500|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan beberapa field yaitu field NamaPegawai dan Gaji\n",
    "df.select(\"NamaPegawai\", \"Gaji\").show()\n",
    "\n",
    "# Menampilkan data pegawa yang gajinya diatas 3000\n",
    "df.filter(df[\"Gaji\"] > 3000).show()\n",
    "\n",
    "# Melakukan sebuah groupBy lalu menghirung rata rata dari gaji setiap divisi jembatan\n",
    "df.groupBy(\"Jabatan\").avg(\"Gaji\").show()\n",
    "\n",
    "# Untuk melakukan fungsi aggregasi seperti mean, max, sum maka kita harus melakukan import library terlebih dahulu\n",
    "from pyspark.sql.functions import mean, max, sum\n",
    "\n",
    "# MElakukan sebuah groupby untuk menyatukan seluruh data lalu menghitung rata - rata total dari gaji\n",
    "df.groupby().agg(mean(df[\"Gaji\"]).alias(\"Rata - Rata Gaji\")).show()\n",
    "\n",
    "# MElakukan sebuah groupby untuk menyatukan seluruh data lalu menghitung nilai maksimal total dari gaji\n",
    "df.groupBy().agg(max(df[\"Gaji\"]).alias(\"Nilai Maksimum Dari Gaji\")).show()\n",
    "\n",
    "# MElakukan sebuah groupby untuk menyatukan seluruh data lalu menghitung jumlah total dari gaji\n",
    "df.groupBy().agg(sum(df[\"Gaji\"]).alias(\"Total Keseluruhan Gaji\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2aa42-53ae-42ee-ad2d-f9b6abf6d552",
   "metadata": {},
   "source": [
    "## Tugas 3: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2980879b-55a7-4fc4-bb86-03f3328b306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----+------------------+\n",
      "|NamaPegawai|          Jabatan|Gaji|TunjanganKesehatan|\n",
      "+-----------+-----------------+----+------------------+\n",
      "|       Budi|    IT Consultant|5000|             250.0|\n",
      "|       Figo|      IT Software|4000|             200.0|\n",
      "|       Kana|Android Developer|3500|               0.0|\n",
      "|       Zico|    Web Developer|3000|               0.0|\n",
      "+-----------+-----------------+----+------------------+\n",
      "\n",
      "+-----------+-----------------+----+------------------+---------+\n",
      "|NamaPegawai|          Jabatan|Gaji|TunjanganKesehatan|TotalGaji|\n",
      "+-----------+-----------------+----+------------------+---------+\n",
      "|       Budi|    IT Consultant|5000|             250.0|   5250.0|\n",
      "|       Figo|      IT Software|4000|             200.0|   4200.0|\n",
      "|       Kana|Android Developer|3500|               0.0|   3500.0|\n",
      "|       Zico|    Web Developer|3000|               0.0|   3000.0|\n",
      "+-----------+-----------------+----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# menggunakan when dimana berfungsi untuk menjalankan aksi jika kondisi true\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Buat kolom tunjangan dimana tunjangan diberikan pada gaji yang lebih besar dari 3500\n",
    "df = df.withColumn('TunjanganKesehatan', when(df['Gaji'] > 3500, df['Gaji'] * 0.05).otherwise(0))\n",
    "\n",
    "# Menampilkan tunjangan\n",
    "df.show()\n",
    "\n",
    "# Membuat total keseluruhan gaji dari Gaji + Tunjangan Kesehatan\n",
    "df = df.withColumn(\"TotalGaji\", df[\"Gaji\"] + df[\"TunjanganKesehatan\"])\n",
    "\n",
    "# Menampilkan total keseluruhan gaji\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f894037-ead8-4a07-9de6-b8bc4197fc1a",
   "metadata": {},
   "source": [
    "## Tugas 4: Implementasikan window function untuk menghitung running totals atau rangking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b11b114b-794a-441b-9f91-9cc5dd5ba3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----+------------------+---------+-----------------------------+-------+\n",
      "|NamaPegawai|          Jabatan|Gaji|TunjanganKesehatan|TotalGaji|NilaiMaksimumGajiDiJabatannya|Ranking|\n",
      "+-----------+-----------------+----+------------------+---------+-----------------------------+-------+\n",
      "|        Mia|Android Developer|1200|               0.0|   1200.0|                       3500.0|      1|\n",
      "|       Kana|Android Developer|3500|               0.0|   3500.0|                       3500.0|      2|\n",
      "|     Farrel|    IT Consultant|3000|               0.0|   3000.0|                       5250.0|      1|\n",
      "|       Budi|    IT Consultant|5000|             250.0|   5250.0|                       5250.0|      2|\n",
      "|       Arya|      IT Software|3300|               0.0|   3300.0|                       4200.0|      1|\n",
      "|       Figo|      IT Software|4000|             200.0|   4200.0|                       4200.0|      2|\n",
      "|       Zico|    Web Developer|3000|               0.0|   3000.0|                       5250.0|      1|\n",
      "|    Alucard|    Web Developer|5000|             250.0|   5250.0|                       5250.0|      2|\n",
      "+-----------+-----------------+----+------------------+---------+-----------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Membuat sebuah list dengan kumpulan tupple untuk membuat sebuah dataframe\n",
    "data = [\n",
    "    ('Farrel', 'IT Consultant', 3000, 0.0, 3000.0),     # Pekerjaan paling sulit\n",
    "    ('Arya', 'IT Software', 3300, 0.0, 3300.0),       # Pekerjaan cukup sulit\n",
    "    ('Mia', 'Android Developer', 1200, 0.0, 1200.0), # Pekerjaan Menengah\n",
    "    ('Alucard', 'Web Developer', 5000, 250.0, 5250.0)      # Pekerjaan yang Lebih mudah\n",
    "]\n",
    "\n",
    "# Membuat sebuah kolom untuk dataframe nantinya\n",
    "columns = [\"NamaPegawai\", \"Jabatan\", \"Gaji\", \"TunjanganKesehatan\", \"TotalGaji\"]\n",
    "\n",
    "# Membuat sebuah dataframe dengan nilai data dan kolom yang sudah dibuat sebelumnya\n",
    "df2 = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Menggabungkan dataframe dari variabel df dengan df2\n",
    "df = df.union(df2)\n",
    "\n",
    "# Mengimport library window untuk membuat aturan dalam melihat baris yang lain\n",
    "from pyspark.sql.window import Window\n",
    "# Mengimport library max dan rank untuk melihat nilai maksimum dan ranking\n",
    "from pyspark.sql.functions import max, rank\n",
    "\n",
    "# Menentukan aturan window\n",
    "# Pada kasus ini aturannya adalah melihat baris lain berdasarkan Jabatan maka dibuat dulu sebuah partisi Jabatan diurutkan berdasarkan TotalGaji\n",
    "windowRule = Window.partitionBy(\"Jabatan\")\n",
    "\"\"\"\n",
    "Melakukan fungsi agregasi tapi tidak melakukan groupBy tetapi menggunakan over yang\n",
    "membuat fungsi agregasi dilakukan berdasarkan daerah yang dipilih yaitu Jabatan tetapi\n",
    "tidak merubah nilai aslinya\n",
    "\"\"\"\n",
    "# Menambahkan nilai maksimum gaji di setiap jabtannya \n",
    "df = df.withColumn(\"NilaiMaksimumGajiDiJabatannya\", max(df[\"TotalGaji\"]).over(windowRule))\n",
    "# Menampilkan nilai rangking dari gaji\n",
    "df = df.withColumn(\"Ranking\", rank().over(windowRule.orderBy(\"TotalGaji\")))\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589854b-f8af-4d60-9d93-9eebe33a9485",
   "metadata": {},
   "source": [
    "## Tugas 5:\n",
    "### Unduh dataset besar dari Kaggle atau sumber lainnya.\n",
    "### Input data csv yang telah di download, kemudian load dan simpan data ke dalam pyspark.\n",
    "### Setelah data berhasil di load menggunakan pyspark, lakukan manipulasi data untuk memperoleh informasi yang dibutuhkanS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22b5702f-2884-4dc1-8745-854a7daaf2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|  NaN|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|  NaN|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|  NaN|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male| NaN|    0|    0|          330877| 8.4583|  NaN|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|  NaN|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|  NaN|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|  NaN|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|  NaN|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|  NaN|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|  NaN|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|  NaN|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|  NaN|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male| NaN|    0|    0|          244373|   13.0|  NaN|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|  NaN|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female| NaN|    0|    0|            2649|  7.225|  NaN|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Mengubah data csv menjadi dataframe pyspark\n",
    "\n",
    "# Pertama saya gunaakan pandas\n",
    "import pandas as pd\n",
    "\n",
    "# lalu buat jadi dataframe pandas \n",
    "df_titanic = pd.read_csv('titanic.csv', index_col=\"PassengerId\")\n",
    "\n",
    "# lalu ubah ke pyspark dataframe\n",
    "df_titanic = spark.createDataFrame(df_titanic)\n",
    "df_titanic.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3df699d3-d06f-4b32-b511-fbf5db0b2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----------+---------------+-------------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|   Embarked|Passenger Caste|TotalFamilies|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----------+---------------+-------------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|Southampton|    Lower Class|            1|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  Cherbourg|    Upper Class|            1|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|Southampton|    Lower Class|            0|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|Southampton|    Upper Class|            1|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|Southampton|    Lower Class|            0|\n",
      "|       0|     3|    Moran, Mr. James|  male| NaN|    0|    0|          330877| 8.4583| Queenstown|    Lower Class|            0|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|Southampton|    Upper Class|            0|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|Southampton|    Lower Class|            4|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|Southampton|    Lower Class|            2|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|  Cherbourg|   Middle Class|            1|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|Southampton|    Lower Class|            2|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|Southampton|    Upper Class|            0|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|Southampton|    Lower Class|            0|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|Southampton|    Lower Class|            6|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|Southampton|    Lower Class|            0|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|Southampton|   Middle Class|            0|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| Queenstown|    Lower Class|            5|\n",
      "|       1|     2|Williams, Mr. Cha...|  male| NaN|    0|    0|          244373|   13.0|Southampton|   Middle Class|            0|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|Southampton|    Lower Class|            1|\n",
      "|       1|     3|Masselmani, Mrs. ...|female| NaN|    0|    0|            2649|  7.225|  Cherbourg|    Lower Class|            0|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----------+---------------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Menghapus kolom Cabin dengan alasan terdapat 70% informasi cabin penumpang hilang akibat tragedi oleh sebab itu kolom cabin akan dihapus.\n",
    "df_titanic = df_titanic.drop('Cabin')\n",
    "\n",
    "# Mengkategorikan kasta penumpang berdasarkan level penumpang atau PClass. 1 untuk Bangsawan, 2 untuk Menengah, 3 untuk Rakyat Biasa.\n",
    "df_titanic = df_titanic.withColumn(\n",
    "    \"Passenger Caste\",\n",
    "    when(df_titanic[\"Pclass\"] == \"1\", \"Upper Class\")\n",
    "    .when(df_titanic[\"Pclass\"] == \"2\", \"Middle Class\")\n",
    "    .otherwise(\"Lower Class\")\n",
    ")\n",
    "\n",
    "# Mendetailkan informasi pelabuhan keberangkatan pada Embarked untuk mengetahui asal penumpang dari mana.\n",
    "df_titanic = df_titanic.withColumn(\n",
    "    \"Embarked\",\n",
    "    when(df_titanic[\"Embarked\"] == \"C\", \"Cherbourg\")\n",
    "    .when(df_titanic[\"Embarked\"] == \"Q\", \"Queenstown\")\n",
    "    .when(df_titanic[\"Embarked\"] == \"S\", \"Southampton\")\n",
    "    .otherwise(df_titanic[\"Embarked\"])  # untuk nilai lain tetap sama\n",
    ")\n",
    "\n",
    "# Terakhir mentotalkan jumlah keluarga yang dimiliki dari SibSp + Parch. \n",
    "df_titanic = df_titanic.withColumn(\"TotalFamilies\", df_titanic['SibSp'] + df_titanic[\"Parch\"])\n",
    "\n",
    "df_titanic.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
